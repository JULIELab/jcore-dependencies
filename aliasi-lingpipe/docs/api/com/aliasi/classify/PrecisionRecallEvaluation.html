<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!--NewPage-->
<HTML>
<HEAD>
<!-- Generated by javadoc (build 1.6.0_14) on Thu Jun 23 19:27:25 EDT 2011 -->
<TITLE>
PrecisionRecallEvaluation (LingPipe API)
</TITLE>

<META NAME="date" CONTENT="2011-06-23">

<LINK REL ="stylesheet" TYPE="text/css" HREF="../../../stylesheet.css" TITLE="Style">

<SCRIPT type="text/javascript">
function windowTitle()
{
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="PrecisionRecallEvaluation (LingPipe API)";
    }
}
</SCRIPT>
<NOSCRIPT>
</NOSCRIPT>

</HEAD>

<BODY BGCOLOR="white" onload="windowTitle();">
<HR>


<!-- ========= START OF TOP NAVBAR ======= -->
<A NAME="navbar_top"><!-- --></A>
<A HREF="#skip-navbar_top" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_top_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../com/aliasi/classify/PerceptronClassifier.html" title="class in com.aliasi.classify"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../com/aliasi/classify/RankedClassification.html" title="class in com.aliasi.classify"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../index.html?com/aliasi/classify/PrecisionRecallEvaluation.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="PrecisionRecallEvaluation.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_top"></A>
<!-- ========= END OF TOP NAVBAR ========= -->

<HR>
<!-- ======== START OF CLASS DATA ======== -->
<H2>
<FONT SIZE="-1">
com.aliasi.classify</FONT>
<BR>
Class PrecisionRecallEvaluation</H2>
<PRE>
<A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">java.lang.Object</A>
  <IMG SRC="../../../resources/inherit.gif" ALT="extended by "><B>com.aliasi.classify.PrecisionRecallEvaluation</B>
</PRE>
<HR>
<DL>
<DT><PRE>public class <B>PrecisionRecallEvaluation</B><DT>extends <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</A></DL>
</PRE>

<P>
A <code>PrecisionRecallEvaluation</code> collects and reports a
 suite of descriptive statistics for binary classification tasks.
 The basis of a precision recall evaluation is a matrix of counts
 of reference and response classifications.  Each cell in the matrix
 corresponds to a method returning a long integer count.

 <blockquote>
 <font size='-1'>
 <table border='1' cellpadding='10'>
 <tr><td colspan='2' rowspan='2' bordercolor='white'>&nbsp;</td>
     <td colspan='2' align='center'><b><i>Response</i></b></td>
     <td rowspan='2' align='center' valign='bottom'><i>Reference Totals</i></td>
 </tr>
 <tr>
     <td align='center'><i>true</i></td>
     <td align='center'><i>false</i></td></tr>
 <tr><td rowspan='2'><i><b>Refer<br>-ence</b></i></td><td align='right'><i>true</i></td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#truePositive()"><CODE>truePositive()</CODE></A> (TP)</td><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#falseNegative()"><CODE>falseNegative()</CODE></A> (FN)</td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveReference()"><CODE>positiveReference()</CODE></A> (TP+FN)</td>
 </tr>
 <tr><td align='right'><i>false</i></td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#falsePositive()"><CODE>falsePositive()</CODE></A> (FP)</td><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#trueNegative()"><CODE>trueNegative()</CODE></A> (TN)</td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeReference()"><CODE>negativeReference()</CODE></A> (FP+TN)</td>
 </tr>
 <tr><td colspan='2' align='right'><i>Response Totals</td><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveResponse()"><CODE>positiveResponse()</CODE></A> (TP+FP)</td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeResponse()"><CODE>negativeResponse()</CODE></A> (FN+TN)</td>
     <td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#total()"><CODE>total()</CODE></A> (TP+FN+FP+TN)</td>
 </tr>
 </table>
 </font>
 </blockquote>

 The most basic statistic is accuracy, which is the number of
 correct responses divided by the total number of cases.
 
 <blockquote><code>
 <b>accuracy</b>()</code>
 = correct() / total()
 </code></blockquote>
 
 This class derives its name from the following four statistics,
 which are illustrated in the four tables.  
 
 <blockquote><code>
 <b>recall</b>()
 = truePositive() / positiveReference()
 </code></blockquote>
 
 <blockquote><code>
 <b>precision</b>()
  = truePositive() / positiveResponse()
 </code></blockquote>
 
 <blockquote><code>
 <b>rejectionRecall</b>()
 = trueNegative() / negativeReference()
 </code></blockquote>
 
 <blockquote><code>
 <b>rejectionPrecision</b>()
  = trueNegative() / negativeResponse()
 </code></blockquote>
 
 Each measure is defined to be the green count divided by the green
 plus red count in the corresponding table:

 <blockquote>

 <table border='0' cellpadding='10'>

 <tr><td>

 <table border='1' cellpadding='3'>
 <tr><td colspan='2' rowspan='2' bordercolor='white' valign='top'>
        <b>Recall</b>
     </td>
     <td colspan='3' align='center'><i>Response</i></td></tr>
 <tr>
     <td>True</td>
     <td>False</td></tr>
 <tr><td rowspan='3'><i>Refer<br>-ence</i></td><td>True</td>
     <td bgcolor='green'><b><big>+</big></b></td><td bgcolor='red'><b><big>-</big></b></td></tr>
 <tr><td>False</td>
     <td>&nbsp;</td><td>&nbsp;</td></tr>
 </table>

 </td><td>

 <table border='1' cellpadding='3'>
 <tr><td colspan='2' rowspan='2' bordercolor='white' valign='top'>
        <b>Precision</b>
     </td>
     <td colspan='3' align='center'><i>Response</i></td></tr>
 <tr>
     <td>True</td>
     <td>False</td></tr>
 <tr><td rowspan='3'><i>Refer<br>-ence</i></td><td>True</td>
     <td bgcolor='green'><b><big>+</big></b></td><td>&nbsp;</td></tr>
 <tr><td>False</td>
     <td bgcolor='red'><b><big>-</big></b></td><td>&nbsp;</td></tr>
 </table>

 </td></tr>
 <tr><td>

 <table border='1' cellpadding='3'>
 <tr><td colspan='2' rowspan='2' bordercolor='white' valign='top'>
        <b>Rejection <br>Recall</b>
     </td>
     <td colspan='3' align='center'><i>Response</i></td></tr>
 <tr>
     <td>True</td>
     <td>False</td></tr>
 <tr><td rowspan='3'><i>Refer<br>-ence</i></td><td>True</td>
     <td>&nbsp;</td><td>&nbsp;</td></tr>
 <tr><td>False</td>
     <td bgcolor='red'><b><big>-</big></b></td><td bgcolor='green'><b><big>+</big></b></td></tr>
 </table>

 </td><td>

 <table border='1' cellpadding='3'>
 <tr><td colspan='2' rowspan='2' bordercolor='white' valign='top'>
        <b>Rejection <br>Precision</b>
     </td>
     <td colspan='3' align='center'><i>Response</i></td></tr>
 <tr>
     <td>True</td>
     <td>False</td></tr>
 <tr><td rowspan='3'><i>Refer<br>-ence</i></td><td>True</td>
     <td>&nbsp;</td><td bgcolor='red'><b><big>-</big></b></td></tr>
 <tr><td>False</td>
     <td>&nbsp;</td><td bgcolor='green'><b><big>+</big></b></td></tr>
 </table>

 </td></tr></table>
 </blockquote>

 This picture clearly illustrates the relevant
 dualities.  Precision is the dual to recall if the reference and
 response are switched (the matrix is transposed).  Similarly,
 rejection recall is dual to recall with true and false labels
 switched (reflection around each axis in turn); rejection precision is
 similarly dual to precision.
 
 <P>Precision and recall may be combined by weighted geometric
 averaging by using the f-measure statistic, with
 <code>&beta;</code> between 0 and infinity being the relative
 weight of precision, with 1 being a neutral value.

 <blockquote><code>
 <b>fMeasure</b>() = fMeasure(1)
 </code></blockquote>
 
 <blockquote><code>
 <b>fMeasure</b>(&beta;)
  = (1 + &beta;<sup><sup>2</sup></sup>) 
  * <A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#precision()"><CODE>precision()</CODE></A>
  * <A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#recall()"><CODE>recall()</CODE></A>
  / (<A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#recall()"><CODE>recall()</CODE></A> + &beta;<sup><sup>2</sup></sup> * <A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#precision()"><CODE>precision()</CODE></A>)
 </code></blockquote>
 
 <P>There are four traditional measures of binary classification,
 which are as follows.
 
 <blockquote><code>
 <b>fowlkesMallows</b>()
 = truePositive() / (precision() * recall())<sup><sup>(1/2)</sup></sup>
 </code></blockquote>

 <blockquote><code>
 <b>jaccardCoefficient</b>()
 = truePositive() / (total() - trueNegative())
 </code></blockquote>

 <blockquote><code>
 <b>yulesQ</b>()
 = (truePositive() * trueNegative() - falsePositive() * falseNegative())
 / (truePositive() * trueNegative() + falsePositive() * falsePositive())
 </code></blockquote>
 <blockquote><code>
 <b>yulesY</b>()
 = ((truePositive() * trueNegative())<sup><sup>(1/2)</sup></sup>
    - (falsePositive() * falseNegative())<sup><sup>(1/2)</sup></sup>)
 <br>/ ((truePositive() * trueNegative())<sup><sup>(1/2)</sup></sup> + (falsePositive() * falsePositive())<sup><sup>(1/2)</sup></sup>)
 </code></blockquote>

 <P>Replacing precision and recall with their definitions,
 <code>TP/(TP+FP)</code> and <code>TP/(TP+FN)</code>:

 <font size='-1'>
 <pre>
      F<sub><sub>1</sub></sub>
      = 2 * (TP/(TP+FP)) * (TP/(TP+FN)) 
        / (TP/(TP+FP) + TP/(TP+FN))     
      = 2 * (TP*TP / (TP+FP)(TP+FN))
        / (TP*(TP+FN)/(TP+FP)(TP+FN) + TP*(TP+FP)/(TP+FN)(TP+FP))
      = 2 * (TP / (TP+FP)(TP+FN))
        / ((TP+FN)/(TP+FP)(TP+FN) + (TP+FP)/(TP+FN)(TP+FP))
      = 2 * TP / 
        / ((TP+FN) + (TP+FP))
      = 2*TP / (2*TP + FP + FN)</pre></font>

 Thus the F<sub><sub>1</sub></sub>-measure is very closely related to the Jaccard
 coefficient, <code>TP/(TP+FP+FN)</code>.  Like the Jaccard
 coefficient, the F measure does not vary with varying true
 negative counts.  Rejection precision and recall do vary with
 changes in true negative count.

 <P>Basic reference and response likelihoods are computed by
 frequency.

 <blockquote><code>
 <b>referenceLikelihood</b>() = positiveReference() / total()
 </code></blockquote>

 <blockquote><code>
 <b>responseLikelihood</b>() = positiveResponse() / total()
 </code></blockquote>

 An algorithm that chose responses at random according to the
 response likelihood would have the following accuracy against
 test cases chosen at random according to the reference likelihood:
 
 <blockquote><code>
 <b>randomAccuracy</b>()
 = referenceLikelihood() * responseLikelihood()
 + (1 - referenceLikelihood()) * (1 - responseLikelihood())
 </code></blockquote>

 The two summands arise from the likelihood of true positive and the
 likelihood of a true negative.  From random accuracy, the
 &kappa;-statistic is defined by dividing out the random accuracy
 from the accuracy, in some way giving a measure of performance
 above a baseline expectation.
 
 <blockquote><code>
 <b>kappa</b>()
 = <i>kappa</i>(accuracy(),randomAccuracy())
 </code></blockquote>

 <blockquote><code>
 <i><b>kappa</b></i>(p,e)
 = (p - e) / (1 - e)
 </code></blockquote>
 
 <P>There are two alternative forms of the &kappa;-statistic, both
 of which attempt to correct for putative bias in the estimation of
 random accuracy.  The first involves computing the random accuracy
 by taking the average of the reference and response likelihoods to
 be the baseline reference and response likelihood, and squaring the
 result to get the so-called unbiased random accuracy and the
 unbiased &kappa;-statistic:

 <blockquote><code>
 <b>randomAccuracyUnbiased</b>()
 = avgLikelihood()<sup><sup>2</sup></sup>
 + (1 - avgLikelihood())<sup><sup>2</sup></sup>
 <br>
 avgLikelihood() = (referenceLikelihood() + responseLikelihood()) / 2
 </code></blockquote>

 <blockquote><code>
 <b>kappaUnbiased</b>()
 = <i>kappa</i>(accuracy(),randomAccuracyUnbiased())
 </code></blockquote>

 <P>Kappa can also be adjusted for the prevalence of positive
 reference cases, which leads to the following simple definition:
 
 <blockquote><code>
 <b>kappaNoPrevalence</b>()
 = (2 * accuracy()) - 1
 </code></blockquote>

<P>Pearson's C<sup><sup>2</sup></sup> statistic is provided by
 the following method:
 
 <blockquote><code>
 <b>chiSquared</b>() 
 = total() * phiSquared()
 </code></blockquote>
 
 <blockquote><code>
 <b>phiSquared</b>()
 = ((truePositive()*trueNegative()) * (falsePositive()*falseNegative()))<sup><sup>2</sup></sup>
 <br>/ ((truePositive()+falseNegative()) * (falsePositive()+trueNegative()) * (truePositive()+falsePositive()) * (falseNegative()+trueNegative()))
 </code></blockquote>

 <P>The accuracy deviation is the deviation of the average number of
 positive cases in a binomial distribution with accuracy equal to
 the classification accuracy and number of trials equal to the total
 number of cases.
 
 <blockquote><code>
 <b>accuracyDeviation</b>()
 = (accuracy() * (1 - accuracy()) / total())<sup><sup>(1/2)</sup></sup>
 </code></blockquote>

 This number can be used to provide error intervals around the 
 accuracy results.

 <P>Using the following three tables as examples:

 <blockquote>
 <table border='0' cellpadding='5'>
 <tr>

 <td>
 <table border='1' cellpadding='3'>
 <tr><td colspan='4'><b>Cab-vs-All</b></td></tr>
 <tr><td colspan='2' rowspan='2' bordercolor='white'>&nbsp;</td>
     <td colspan='3' align='center'><b><i>Response</i></b></td></tr>
 <tr>
     <td><i>Cab</i></td>
     <td><i>Other</i></td></tr>
 <tr><td rowspan='3'><i><b>Refer<br>-ence</b></i></td><td><i>Cab</i></td>
     <td bgcolor='#CCCCFF'>9</td><td>3</td></tr>
 <tr><td><i>Other</i></td>
     <td>4</td><td bgcolor='#CCCCFF'>11</td></tr>
 </table>
 </td>

 <td>
 <table border='1' cellpadding='3'>
 <tr><td colspan='4'><b>Syrah-vs-All</b></td></tr>
 <tr><td colspan='2' rowspan='2' bordercolor='white'>&nbsp;</td>
     <td colspan='3' align='center'><b><i>Response</i></b></td></tr>
 <tr>
     <td><i>Syrah</i></td>
     <td><i>Other</i></td></tr>
 <tr><td rowspan='3'><i><b>Refer<br>-ence</b></i></td><td><i>Syrah</i></td>
     <td bgcolor='#CCCCFF'>5</td><td>4</td></tr>
 <tr><td><i>Other</i></td>
     <td>4</td><td bgcolor='#CCCCFF'>14</td></tr>
 </table>
 </td>

 <td>
 <table border='1' cellpadding='3'>
 <tr><td colspan='4'><b>Pinot-vs-All</b></td></tr>
 <tr><td colspan='2' rowspan='2' bordercolor='white'>&nbsp;</td>
     <td colspan='3' align='center'><b><i>Response</i></b></td></tr>
 <tr>
     <td><i>Pinot</i></td>
     <td><i>Other</i></td></tr>
 <tr><td rowspan='3'><i><b>Refer<br>-ence</b></i></td><td><i>Pinot</i></td>
     <td bgcolor='#CCCCFF'>4</td><td>2</td></tr>
 <tr><td><i>Other</i></td>
     <td>1</td><td bgcolor='#CCCCFF'>20</td></tr>
 </table>
 </td>

 </tr>
 </table>

 </blockquote>

 The various statistics evaluate to the following values:

 <blockquote>
 <table border='1' cellpadding='5'>
 <tr><td><i>Method</i></td>
     <td><i>Cabernet</i></td>
     <td><i>Syrah</i></td>
     <td><i>Pinot</i></td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveReference()"><CODE>positiveReference()</CODE></A></td>
     <td>12</td><td>9</td><td>6</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeReference()"><CODE>negativeReference()</CODE></A></td>
     <td>15</td><td>18</td><td>21</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveResponse()"><CODE>positiveResponse()</CODE></A></td>
     <td>13</td><td>9</td><td>5</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeResponse()"><CODE>negativeResponse()</CODE></A></td>
     <td>14</td><td>18</td><td>22</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#correctResponse()"><CODE>correctResponse()</CODE></A></td>
     <td>20</td><td>19</td><td>24</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#total()"><CODE>total()</CODE></A></td>
     <td>27</td><td>27</td><td>27</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#accuracy()"><CODE>accuracy()</CODE></A></td>
     <td>0.7407</td><td>0.7037</td><td>0.8889</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#recall()"><CODE>recall()</CODE></A></td>
     <td>0.7500</td><td>0.5555</td><td>0.6666</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#precision()"><CODE>precision()</CODE></A></td>
     <td>0.6923</td><td>0.5555</td><td>0.8000</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#rejectionRecall()"><CODE>rejectionRecall()</CODE></A></td>
     <td>0.7333</td><td>0.7778</td><td>0.9524</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#rejectionPrecision()"><CODE>rejectionPrecision()</CODE></A></td>
     <td>0.7858</td><td>0.7778</td><td>0.9091</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure()"><CODE>fMeasure()</CODE></A></td>
     <td>0.7200</td><td>0.5555</td><td>0.7272</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fowlkesMallows()"><CODE>fowlkesMallows()</CODE></A></td>
     <td>12.49</td><td>9.00</td><td>5.48</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#jaccardCoefficient()"><CODE>jaccardCoefficient()</CODE></A></td>
     <td>0.5625</td><td>0.3846</td><td>0.5714</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#yulesQ()"><CODE>yulesQ()</CODE></A></td>
     <td>0.7838</td><td>0.6279</td><td>0.9512</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#yulesY()"><CODE>yulesY()</CODE></A></td>
     <td>0.4835</td><td>0.3531</td><td>0.7269</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#referenceLikelihood()"><CODE>referenceLikelihood()</CODE></A></td>
     <td>0.4444</td><td>0.3333</td><td>0.2222</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#responseLikelihood()"><CODE>responseLikelihood()</CODE></A></td>
     <td>0.4815</td><td>0.3333</td><td>0.1852</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#randomAccuracy()"><CODE>randomAccuracy()</CODE></A></td>
     <td>0.5021</td><td>0.5556</td><td>0.6749</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappa()"><CODE>kappa()</CODE></A></td>
     <td>0.4792</td><td>0.3333</td><td>0.6583</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#randomAccuracyUnbiased()"><CODE>randomAccuracyUnbiased()</CODE></A></td>
     <td>0.5027</td><td>0.5556</td><td>0.6756</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappaUnbiased()"><CODE>kappaUnbiased()</CODE></A></td>
     <td>0.4789</td><td>0.3333</td><td>0.6575</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappaNoPrevalence()"><CODE>kappaNoPrevalence()</CODE></A></td>
     <td>0.4814</td><td>0.4074</td><td>0.7778</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#chiSquared()"><CODE>chiSquared()</CODE></A></td>
     <td>6.2382</td><td>3.0000</td><td>11.8519</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#phiSquared()"><CODE>phiSquared()</CODE></A></td>
     <td>0.2310</td><td>0.1111</td><td>0.4390</td></tr>
 <tr><td><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#accuracyDeviation()"><CODE>accuracyDeviation()</CODE></A></td>
     <td>0.0843</td><td>0.0879</td><td>0.0605</td></tr>
 </table>
 </blockquote>
<P>

<P>
<DL>
<DT><B>Since:</B></DT>
  <DD>LingPipe2.1</DD>
<DT><B>Version:</B></DT>
  <DD>2.1</DD>
<DT><B>Author:</B></DT>
  <DD>Bob Carpenter</DD>
</DL>
<HR>

<P>

<!-- ======== CONSTRUCTOR SUMMARY ======== -->

<A NAME="constructor_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Constructor Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#PrecisionRecallEvaluation()">PrecisionRecallEvaluation</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construct a precision-recall evaluation with all counts set to
 zero.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#PrecisionRecallEvaluation(long, long, long, long)">PrecisionRecallEvaluation</A></B>(long&nbsp;tp,
                          long&nbsp;fn,
                          long&nbsp;fp,
                          long&nbsp;tn)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Construction a precision-recall evaluation initialized with the
 specified counts.</TD>
</TR>
</TABLE>
&nbsp;
<!-- ========== METHOD SUMMARY =========== -->

<A NAME="method_summary"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="2"><FONT SIZE="+2">
<B>Method Summary</B></FONT></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#accuracy()">accuracy</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the sample accuracy of the responses.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#accuracyDeviation()">accuracyDeviation</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the standard deviation of the accuracy.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;void</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#addCase(boolean, boolean)">addCase</A></B>(boolean&nbsp;reference,
        boolean&nbsp;response)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Adds a case with the specified reference and response
 classifications.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#chiSquared()">chiSquared</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the &chi;<sup>2</sup> value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#correctResponse()">correctResponse</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of cases where the response is correct.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#falseNegative()">falseNegative</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of false negative cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#falsePositive()">falsePositive</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of false positive cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure()">fMeasure</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the F<sub><sub>1</sub></sub> measure.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure(double)">fMeasure</A></B>(double&nbsp;beta)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the <code>F<sub><sub>&beta;</sub></sub></code> value for
 the specified <code>&beta;</code>.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>static&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure(double, double, double)">fMeasure</A></B>(double&nbsp;beta,
         double&nbsp;recall,
         double&nbsp;precision)</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the F<sub><sub>&beta;</sub></sub> measure for
 a specified &beta;, recall and precision values.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fowlkesMallows()">fowlkesMallows</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the Fowlkes-Mallows score.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#incorrectResponse()">incorrectResponse</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of cases where the response is incorrect.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#jaccardCoefficient()">jaccardCoefficient</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the Jaccard coefficient.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappa()">kappa</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the kappa statistic.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappaNoPrevalence()">kappaNoPrevalence</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the kappa statistic adjusted for
 prevalence.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#kappaUnbiased()">kappaUnbiased</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the value of the unbiased kappa statistic.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeReference()">negativeReference</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of negative reference cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#negativeResponse()">negativeResponse</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of negative response cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#phiSquared()">phiSquared</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the &phi;<sup>2</sup> value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveReference()">positiveReference</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of positive reference cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#positiveResponse()">positiveResponse</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of positive response cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#precision()">precision</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the precision.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#randomAccuracy()">randomAccuracy</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The probability that the reference and response are the same if
 they are generated randomly according to the reference and
 response likelihoods.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#randomAccuracyUnbiased()">randomAccuracyUnbiased</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The probability that the reference and the response are the same
 if the reference and response likelihoods are both the average
 of the sample reference and response likelihoods.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#recall()">recall</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the recall.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#referenceLikelihood()">referenceLikelihood</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the sample reference likelihood, or prevalence, which
 is the number of positive references divided * by the total
 number of cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#rejectionPrecision()">rejectionPrecision</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the rejection prection, or selectivity, value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#rejectionRecall()">rejectionRecall</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the rejection recall, or specificity, value.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#responseLikelihood()">responseLikelihood</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the sample response likelihood, which is the number of
 positive responses divided by the total number of cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;<A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/String.html?is-external=true" title="class or interface in java.lang">String</A></CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#toString()">toString</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns a string-based representation of this evaluation.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#total()">total</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the total number of cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#trueNegative()">trueNegative</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of true negative cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;long</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#truePositive()">truePositive</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Returns the number of true positive cases.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#yulesQ()">yulesQ</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the value of Yule's Q statistic.</TD>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD ALIGN="right" VALIGN="top" WIDTH="1%"><FONT SIZE="-1">
<CODE>&nbsp;double</CODE></FONT></TD>
<TD><CODE><B><A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#yulesY()">yulesY</A></B>()</CODE>

<BR>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Return the value of Yule's Y statistic.</TD>
</TR>
</TABLE>
&nbsp;<A NAME="methods_inherited_from_class_java.lang.Object"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#EEEEFF" CLASS="TableSubHeadingColor">
<TH ALIGN="left"><B>Methods inherited from class java.lang.<A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</A></B></TH>
</TR>
<TR BGCOLOR="white" CLASS="TableRowColor">
<TD><CODE><A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#clone()" title="class or interface in java.lang">clone</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#equals(java.lang.Object)" title="class or interface in java.lang">equals</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#finalize()" title="class or interface in java.lang">finalize</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#getClass()" title="class or interface in java.lang">getClass</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#hashCode()" title="class or interface in java.lang">hashCode</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notify()" title="class or interface in java.lang">notify</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#notifyAll()" title="class or interface in java.lang">notifyAll</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait()" title="class or interface in java.lang">wait</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait(long)" title="class or interface in java.lang">wait</A>, <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#wait(long, int)" title="class or interface in java.lang">wait</A></CODE></TD>
</TR>
</TABLE>
&nbsp;
<P>

<!-- ========= CONSTRUCTOR DETAIL ======== -->

<A NAME="constructor_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Constructor Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="PrecisionRecallEvaluation()"><!-- --></A><H3>
PrecisionRecallEvaluation</H3>
<PRE>
public <B>PrecisionRecallEvaluation</B>()</PRE>
<DL>
<DD>Construct a precision-recall evaluation with all counts set to
 zero.
<P>
</DL>
<HR>

<A NAME="PrecisionRecallEvaluation(long, long, long, long)"><!-- --></A><H3>
PrecisionRecallEvaluation</H3>
<PRE>
public <B>PrecisionRecallEvaluation</B>(long&nbsp;tp,
                                 long&nbsp;fn,
                                 long&nbsp;fp,
                                 long&nbsp;tn)</PRE>
<DL>
<DD>Construction a precision-recall evaluation initialized with the
 specified counts.
<P>
<DL>
<DT><B>Parameters:</B><DD><CODE>tp</CODE> - True positive count.<DD><CODE>fn</CODE> - False negative count.<DD><CODE>fp</CODE> - False positive count.<DD><CODE>tn</CODE> - True negative count.
<DT><B>Throws:</B>
<DD><CODE><A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/IllegalArgumentException.html?is-external=true" title="class or interface in java.lang">IllegalArgumentException</A></CODE> - If any of the counts are
 negative.</DL>
</DL>

<!-- ============ METHOD DETAIL ========== -->

<A NAME="method_detail"><!-- --></A>
<TABLE BORDER="1" WIDTH="100%" CELLPADDING="3" CELLSPACING="0" SUMMARY="">
<TR BGCOLOR="#CCCCFF" CLASS="TableHeadingColor">
<TH ALIGN="left" COLSPAN="1"><FONT SIZE="+2">
<B>Method Detail</B></FONT></TH>
</TR>
</TABLE>

<A NAME="addCase(boolean, boolean)"><!-- --></A><H3>
addCase</H3>
<PRE>
public void <B>addCase</B>(boolean&nbsp;reference,
                    boolean&nbsp;response)</PRE>
<DL>
<DD>Adds a case with the specified reference and response
 classifications.
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>reference</CODE> - Reference classification.<DD><CODE>response</CODE> - Response classification.</DL>
</DD>
</DL>
<HR>

<A NAME="truePositive()"><!-- --></A><H3>
truePositive</H3>
<PRE>
public long <B>truePositive</B>()</PRE>
<DL>
<DD>Returns the number of true positive cases.  A true positive
 is where both the reference and response are true.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of true positives.</DL>
</DD>
</DL>
<HR>

<A NAME="falsePositive()"><!-- --></A><H3>
falsePositive</H3>
<PRE>
public long <B>falsePositive</B>()</PRE>
<DL>
<DD>Returns the number of false positive cases.  A false positive
 is where the reference is false and response is true.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of false positives.</DL>
</DD>
</DL>
<HR>

<A NAME="trueNegative()"><!-- --></A><H3>
trueNegative</H3>
<PRE>
public long <B>trueNegative</B>()</PRE>
<DL>
<DD>Returns the number of true negative cases.  A true negative
 is where both the reference and response are false.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of true negatives.</DL>
</DD>
</DL>
<HR>

<A NAME="falseNegative()"><!-- --></A><H3>
falseNegative</H3>
<PRE>
public long <B>falseNegative</B>()</PRE>
<DL>
<DD>Returns the number of false negative cases.  A false negative
 is where the reference is true and response is false.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of false negatives.</DL>
</DD>
</DL>
<HR>

<A NAME="positiveReference()"><!-- --></A><H3>
positiveReference</H3>
<PRE>
public long <B>positiveReference</B>()</PRE>
<DL>
<DD>Returns the number of positive reference cases.  A positive
 reference case is one where the reference is true.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of positive references.</DL>
</DD>
</DL>
<HR>

<A NAME="negativeReference()"><!-- --></A><H3>
negativeReference</H3>
<PRE>
public long <B>negativeReference</B>()</PRE>
<DL>
<DD>Returns the number of negative reference cases.  A negative
 reference case is one where the reference is false.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of negative references.</DL>
</DD>
</DL>
<HR>

<A NAME="referenceLikelihood()"><!-- --></A><H3>
referenceLikelihood</H3>
<PRE>
public double <B>referenceLikelihood</B>()</PRE>
<DL>
<DD>Returns the sample reference likelihood, or prevalence, which
 is the number of positive references divided * by the total
 number of cases.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The sample reference likelihood.</DL>
</DD>
</DL>
<HR>

<A NAME="positiveResponse()"><!-- --></A><H3>
positiveResponse</H3>
<PRE>
public long <B>positiveResponse</B>()</PRE>
<DL>
<DD>Returns the number of positive response cases.  A positive
 response case is one where the response is true.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of positive responses.</DL>
</DD>
</DL>
<HR>

<A NAME="negativeResponse()"><!-- --></A><H3>
negativeResponse</H3>
<PRE>
public long <B>negativeResponse</B>()</PRE>
<DL>
<DD>Returns the number of negative response cases.  A negative
 response case is one where the response is false.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of negative responses.</DL>
</DD>
</DL>
<HR>

<A NAME="responseLikelihood()"><!-- --></A><H3>
responseLikelihood</H3>
<PRE>
public double <B>responseLikelihood</B>()</PRE>
<DL>
<DD>Returns the sample response likelihood, which is the number of
 positive responses divided by the total number of cases.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The sample response likelihood.</DL>
</DD>
</DL>
<HR>

<A NAME="correctResponse()"><!-- --></A><H3>
correctResponse</H3>
<PRE>
public long <B>correctResponse</B>()</PRE>
<DL>
<DD>Returns the number of cases where the response is correct.  A
 correct response is one where the reference and response are
 the same.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of correct responses.</DL>
</DD>
</DL>
<HR>

<A NAME="incorrectResponse()"><!-- --></A><H3>
incorrectResponse</H3>
<PRE>
public long <B>incorrectResponse</B>()</PRE>
<DL>
<DD>Returns the number of cases where the response is incorrect.
 An incorrect response is one where the reference and response
 are different.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The number of incorrect responses.</DL>
</DD>
</DL>
<HR>

<A NAME="total()"><!-- --></A><H3>
total</H3>
<PRE>
public long <B>total</B>()</PRE>
<DL>
<DD>Returns the total number of cases.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The total number of cases.</DL>
</DD>
</DL>
<HR>

<A NAME="accuracy()"><!-- --></A><H3>
accuracy</H3>
<PRE>
public double <B>accuracy</B>()</PRE>
<DL>
<DD>Returns the sample accuracy of the responses.  The accuracy is
 just the number of correct responses divided by the total number
 of respones.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The sample accuracy.</DL>
</DD>
</DL>
<HR>

<A NAME="recall()"><!-- --></A><H3>
recall</H3>
<PRE>
public double <B>recall</B>()</PRE>
<DL>
<DD>Returns the recall.  The recall is the number of true positives
 divided by the number of positive references.  This is the
 fraction of positive reference cases that were found by the
 classifier.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The recall value.</DL>
</DD>
</DL>
<HR>

<A NAME="precision()"><!-- --></A><H3>
precision</H3>
<PRE>
public double <B>precision</B>()</PRE>
<DL>
<DD>Returns the precision.  The precision is the number of true
 positives divided by the number of positive respones.  This is
 the fraction of positive responses returned by the classifier
 that were correct.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The precision value.</DL>
</DD>
</DL>
<HR>

<A NAME="rejectionRecall()"><!-- --></A><H3>
rejectionRecall</H3>
<PRE>
public double <B>rejectionRecall</B>()</PRE>
<DL>
<DD>Returns the rejection recall, or specificity, value.
 The rejection recall is the percentage of negative references
 that had negative respones.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The rejection recall value.</DL>
</DD>
</DL>
<HR>

<A NAME="rejectionPrecision()"><!-- --></A><H3>
rejectionPrecision</H3>
<PRE>
public double <B>rejectionPrecision</B>()</PRE>
<DL>
<DD>Returns the rejection prection, or selectivity, value.
 The rejection precision is the percentage of negative responses
 that were negative references.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The rejection precision value.</DL>
</DD>
</DL>
<HR>

<A NAME="fMeasure()"><!-- --></A><H3>
fMeasure</H3>
<PRE>
public double <B>fMeasure</B>()</PRE>
<DL>
<DD>Returns the F<sub><sub>1</sub></sub> measure.  This is the
 result of applying the method <A HREF="../../../com/aliasi/classify/PrecisionRecallEvaluation.html#fMeasure(double)"><CODE>fMeasure(double)</CODE></A> to
 <code>1</code>.  of the method
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The F<sub><sub>1</sub></sub> measure.</DL>
</DD>
</DL>
<HR>

<A NAME="fMeasure(double)"><!-- --></A><H3>
fMeasure</H3>
<PRE>
public double <B>fMeasure</B>(double&nbsp;beta)</PRE>
<DL>
<DD>Returns the <code>F<sub><sub>&beta;</sub></sub></code> value for
 the specified <code>&beta;</code>.
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>beta</CODE> - The <code>&beta;</code> parameter.
<DT><B>Returns:</B><DD>The <code>F<sub><sub>&beta;</sub></sub></code> value.</DL>
</DD>
</DL>
<HR>

<A NAME="jaccardCoefficient()"><!-- --></A><H3>
jaccardCoefficient</H3>
<PRE>
public double <B>jaccardCoefficient</B>()</PRE>
<DL>
<DD>Returns the Jaccard coefficient.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The Jaccard coefficient.</DL>
</DD>
</DL>
<HR>

<A NAME="chiSquared()"><!-- --></A><H3>
chiSquared</H3>
<PRE>
public double <B>chiSquared</B>()</PRE>
<DL>
<DD>Returns the &chi;<sup>2</sup> value.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The &chi;<sup>2</sup> value.</DL>
</DD>
</DL>
<HR>

<A NAME="phiSquared()"><!-- --></A><H3>
phiSquared</H3>
<PRE>
public double <B>phiSquared</B>()</PRE>
<DL>
<DD>Returns the &phi;<sup>2</sup> value.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The &phi;<sup>2</sup> value.</DL>
</DD>
</DL>
<HR>

<A NAME="yulesQ()"><!-- --></A><H3>
yulesQ</H3>
<PRE>
public double <B>yulesQ</B>()</PRE>
<DL>
<DD>Return the value of Yule's Q statistic.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The value of Yule's Q statistic.</DL>
</DD>
</DL>
<HR>

<A NAME="yulesY()"><!-- --></A><H3>
yulesY</H3>
<PRE>
public double <B>yulesY</B>()</PRE>
<DL>
<DD>Return the value of Yule's Y statistic.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The value of Yule's Y statistic.</DL>
</DD>
</DL>
<HR>

<A NAME="fowlkesMallows()"><!-- --></A><H3>
fowlkesMallows</H3>
<PRE>
public double <B>fowlkesMallows</B>()</PRE>
<DL>
<DD>Return the Fowlkes-Mallows score.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The Fowlkes-Mallows score.</DL>
</DD>
</DL>
<HR>

<A NAME="accuracyDeviation()"><!-- --></A><H3>
accuracyDeviation</H3>
<PRE>
public double <B>accuracyDeviation</B>()</PRE>
<DL>
<DD>Returns the standard deviation of the accuracy.  This is
 computed as the deviation of an equivalent accuracy generated
 by a binomial distribution, which is just a sequence of
 Bernoulli (binary) trials.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The standard deviation of the accuracy.</DL>
</DD>
</DL>
<HR>

<A NAME="randomAccuracy()"><!-- --></A><H3>
randomAccuracy</H3>
<PRE>
public double <B>randomAccuracy</B>()</PRE>
<DL>
<DD>The probability that the reference and response are the same if
 they are generated randomly according to the reference and
 response likelihoods.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The accuracy of a random classifier.</DL>
</DD>
</DL>
<HR>

<A NAME="randomAccuracyUnbiased()"><!-- --></A><H3>
randomAccuracyUnbiased</H3>
<PRE>
public double <B>randomAccuracyUnbiased</B>()</PRE>
<DL>
<DD>The probability that the reference and the response are the same
 if the reference and response likelihoods are both the average
 of the sample reference and response likelihoods.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The unbiased random accuracy.</DL>
</DD>
</DL>
<HR>

<A NAME="kappa()"><!-- --></A><H3>
kappa</H3>
<PRE>
public double <B>kappa</B>()</PRE>
<DL>
<DD>Returns the value of the kappa statistic.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The value of the kappa statistic.</DL>
</DD>
</DL>
<HR>

<A NAME="kappaUnbiased()"><!-- --></A><H3>
kappaUnbiased</H3>
<PRE>
public double <B>kappaUnbiased</B>()</PRE>
<DL>
<DD>Returns the value of the unbiased kappa statistic.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The value of the unbiased kappa statistic.</DL>
</DD>
</DL>
<HR>

<A NAME="kappaNoPrevalence()"><!-- --></A><H3>
kappaNoPrevalence</H3>
<PRE>
public double <B>kappaNoPrevalence</B>()</PRE>
<DL>
<DD>Returns the value of the kappa statistic adjusted for
 prevalence.
<P>
<DD><DL>

<DT><B>Returns:</B><DD>The value of the kappa statistic adjusted for
 prevalence.</DL>
</DD>
</DL>
<HR>

<A NAME="toString()"><!-- --></A><H3>
toString</H3>
<PRE>
public <A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/String.html?is-external=true" title="class or interface in java.lang">String</A> <B>toString</B>()</PRE>
<DL>
<DD>Returns a string-based representation of this evaluation.
<P>
<DD><DL>
<DT><B>Overrides:</B><DD><CODE><A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true#toString()" title="class or interface in java.lang">toString</A></CODE> in class <CODE><A HREF="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Object.html?is-external=true" title="class or interface in java.lang">Object</A></CODE></DL>
</DD>
<DD><DL>

<DT><B>Returns:</B><DD>A string-based representation of this evaluation.</DL>
</DD>
</DL>
<HR>

<A NAME="fMeasure(double, double, double)"><!-- --></A><H3>
fMeasure</H3>
<PRE>
public static double <B>fMeasure</B>(double&nbsp;beta,
                              double&nbsp;recall,
                              double&nbsp;precision)</PRE>
<DL>
<DD>Returns the F<sub><sub>&beta;</sub></sub> measure for
 a specified &beta;, recall and precision values.
<P>
<DD><DL>
<DT><B>Parameters:</B><DD><CODE>beta</CODE> - Relative weighting of precision.<DD><CODE>recall</CODE> - Recall value.<DD><CODE>precision</CODE> - Precision value.
<DT><B>Returns:</B><DD>The F<sub><sub>&beta;</sub></sub> measure.</DL>
</DD>
</DL>
<!-- ========= END OF CLASS DATA ========= -->
<HR>


<!-- ======= START OF BOTTOM NAVBAR ====== -->
<A NAME="navbar_bottom"><!-- --></A>
<A HREF="#skip-navbar_bottom" title="Skip navigation links"></A>
<TABLE BORDER="0" WIDTH="100%" CELLPADDING="1" CELLSPACING="0" SUMMARY="">
<TR>
<TD COLSPAN=2 BGCOLOR="#EEEEFF" CLASS="NavBarCell1">
<A NAME="navbar_bottom_firstrow"><!-- --></A>
<TABLE BORDER="0" CELLPADDING="0" CELLSPACING="3" SUMMARY="">
  <TR ALIGN="center" VALIGN="top">
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../overview-summary.html"><FONT CLASS="NavBarFont1"><B>Overview</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-summary.html"><FONT CLASS="NavBarFont1"><B>Package</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#FFFFFF" CLASS="NavBarCell1Rev"> &nbsp;<FONT CLASS="NavBarFont1Rev"><B>Class</B></FONT>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="package-tree.html"><FONT CLASS="NavBarFont1"><B>Tree</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../deprecated-list.html"><FONT CLASS="NavBarFont1"><B>Deprecated</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../index-all.html"><FONT CLASS="NavBarFont1"><B>Index</B></FONT></A>&nbsp;</TD>
  <TD BGCOLOR="#EEEEFF" CLASS="NavBarCell1">    <A HREF="../../../help-doc.html"><FONT CLASS="NavBarFont1"><B>Help</B></FONT></A>&nbsp;</TD>
  </TR>
</TABLE>
</TD>
<TD ALIGN="right" VALIGN="top" ROWSPAN=3><EM>
</EM>
</TD>
</TR>

<TR>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
&nbsp;<A HREF="../../../com/aliasi/classify/PerceptronClassifier.html" title="class in com.aliasi.classify"><B>PREV CLASS</B></A>&nbsp;
&nbsp;<A HREF="../../../com/aliasi/classify/RankedClassification.html" title="class in com.aliasi.classify"><B>NEXT CLASS</B></A></FONT></TD>
<TD BGCOLOR="white" CLASS="NavBarCell2"><FONT SIZE="-2">
  <A HREF="../../../index.html?com/aliasi/classify/PrecisionRecallEvaluation.html" target="_top"><B>FRAMES</B></A>  &nbsp;
&nbsp;<A HREF="PrecisionRecallEvaluation.html" target="_top"><B>NO FRAMES</B></A>  &nbsp;
&nbsp;<SCRIPT type="text/javascript">
  <!--
  if(window==top) {
    document.writeln('<A HREF="../../../allclasses-noframe.html"><B>All Classes</B></A>');
  }
  //-->
</SCRIPT>
<NOSCRIPT>
  <A HREF="../../../allclasses-noframe.html"><B>All Classes</B></A>
</NOSCRIPT>


</FONT></TD>
</TR>
<TR>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
  SUMMARY:&nbsp;NESTED&nbsp;|&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_summary">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_summary">METHOD</A></FONT></TD>
<TD VALIGN="top" CLASS="NavBarCell3"><FONT SIZE="-2">
DETAIL:&nbsp;FIELD&nbsp;|&nbsp;<A HREF="#constructor_detail">CONSTR</A>&nbsp;|&nbsp;<A HREF="#method_detail">METHOD</A></FONT></TD>
</TR>
</TABLE>
<A NAME="skip-navbar_bottom"></A>
<!-- ======== END OF BOTTOM NAVBAR ======= -->

<HR>

</BODY>
</HTML>
